{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11444158,"sourceType":"datasetVersion","datasetId":7100347}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:43:43.317268Z","iopub.execute_input":"2025-04-18T07:43:43.317496Z","iopub.status.idle":"2025-04-18T07:43:43.322101Z","shell.execute_reply.started":"2025-04-18T07:43:43.317479Z","shell.execute_reply":"2025-04-18T07:43:43.321244Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"! git clone https://github.com/broccubali/autisticadventures","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:43:43.322672Z","iopub.execute_input":"2025-04-18T07:43:43.322841Z","iopub.status.idle":"2025-04-18T07:43:45.050505Z","shell.execute_reply.started":"2025-04-18T07:43:43.322827Z","shell.execute_reply":"2025-04-18T07:43:45.049769Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'autisticadventures'...\nremote: Enumerating objects: 67, done.\u001b[K\nremote: Counting objects: 100% (67/67), done.\u001b[K\nremote: Compressing objects: 100% (60/60), done.\u001b[K\nremote: Total 67 (delta 25), reused 15 (delta 4), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (67/67), 3.71 MiB | 9.39 MiB/s, done.\nResolving deltas: 100% (25/25), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset\nimport torch\nimport numpy as np\n\n\nclass CC200Data(Dataset):\n    def __init__(self, path, mapping, labels):\n        super().__init__()\n        self.path = path\n        self.mapping = mapping\n        self.folder = os.listdir(self.path)\n        self.labels = self._map_labels(labels)\n        self.files = [np.loadtxt(f\"{path}/{i}\") for i in self.folder]\n        self.region_indices = self._region_mapping()\n        self.region_coeff = torch.tensor([self._region_coeffs(i) for i in self.files], dtype=torch.float32)\n        self.subnetwork_coeff = [self._subnetwork_coeffs(i) for i in self.files]\n        self.region_start_indices = {}\n        for i in range(1, 8):\n            if i == 1:\n                self.region_start_indices[i] = 0\n            else:\n                self.region_start_indices[i] = self.region_start_indices[i - 1] + len(\n                    self.region_indices[i - 1]\n                )\n\n    def _map_labels(self, mapping):\n        labels = []\n        for i in self.folder:\n            if i[:-14] in mapping.keys():\n                labels.append(mapping[i[:-14]])\n            else:\n                print(i)\n\n        return torch.tensor(labels, dtype=torch.long)\n\n    def _region_coeffs(self, x):\n        b = np.zeros_like(x)\n        y = 0\n        for i in self.region_indices:\n            b[:, y : y + len(self.region_indices[i])] = x[:, self.region_indices[i]]\n            y += len(self.region_indices[i])\n        b = b[:, 15:]\n        return np.corrcoef(b, rowvar=False)\n\n    def _region_mapping(self):\n        region_indices = {i: [] for i in range(0, 8)}\n        for i, j in self.mapping.items():\n            region_indices[j].append(i - 1)\n        return region_indices\n\n    def _subnetwork_coeffs(self, x):\n        correlation_matrices = []\n\n        for file_idx, (region_id, indices) in enumerate(self.region_indices.items()):\n            if not indices:\n                print(f\"[INFO] Region {region_id} has no indices, skipping.\")\n                continue\n\n            submatrix = x[:, indices]\n            std = np.std(submatrix, axis=0)\n\n            zero_std_count = np.sum(std == 0)\n            if zero_std_count > 0:\n                print(f\"[INFO] File {self.folder[file_idx]} - Region {region_id} has {zero_std_count} constant columns.\")\n\n            try:\n                correlation_matrix = np.corrcoef(submatrix, rowvar=False)\n            except Exception as e:\n                print(f\"[ERROR] Correlation failed in region {region_id}\")\n                print(f\"Exception: {e}\")\n                continue\n\n            flat_corr = self._flatten_matrix(correlation_matrix)\n            correlation_matrices.append(torch.tensor(flat_corr, dtype=torch.float32))\n\n        return correlation_matrices\n\n    def _flatten_matrix(self, matrix):\n        idx = np.triu_indices_from(matrix, k=1)\n        return matrix[idx]\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        region_corr = self.region_coeff[idx]\n        subnetwork_corrs = self.subnetwork_coeff[idx]\n        labels = self.labels[idx]\n        return region_corr, subnetwork_corrs, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:43:45.052699Z","iopub.execute_input":"2025-04-18T07:43:45.052926Z","iopub.status.idle":"2025-04-18T07:43:48.484291Z","shell.execute_reply.started":"2025-04-18T07:43:45.052906Z","shell.execute_reply":"2025-04-18T07:43:48.483727Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/broccubali/AutisticAdventures/main/cc200_to_yeo7_mapping.csv\n!wget https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:43:48.484923Z","iopub.execute_input":"2025-04-18T07:43:48.485212Z","iopub.status.idle":"2025-04-18T07:43:50.934326Z","shell.execute_reply.started":"2025-04-18T07:43:48.485194Z","shell.execute_reply":"2025-04-18T07:43:50.933430Z"}},"outputs":[{"name":"stdout","text":"--2025-04-18 07:43:48--  https://raw.githubusercontent.com/broccubali/AutisticAdventures/main/cc200_to_yeo7_mapping.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1319 (1.3K) [text/plain]\nSaving to: ‚Äòcc200_to_yeo7_mapping.csv‚Äô\n\ncc200_to_yeo7_mappi 100%[===================>]   1.29K  --.-KB/s    in 0s      \n\n2025-04-18 07:43:49 (55.4 MB/s) - ‚Äòcc200_to_yeo7_mapping.csv‚Äô saved [1319/1319]\n\n--2025-04-18 07:43:49--  https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv\nResolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.232.16, 52.217.167.0, 52.217.101.158, ...\nConnecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.232.16|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 449443 (439K) [application/octet-stream]\nSaving to: ‚ÄòPhenotypic_V1_0b_preprocessed1.csv‚Äô\n\nPhenotypic_V1_0b_pr 100%[===================>] 438.91K   605KB/s    in 0.7s    \n\n2025-04-18 07:43:50 (605 KB/s) - ‚ÄòPhenotypic_V1_0b_preprocessed1.csv‚Äô saved [449443/449443]\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('autisticadventures/cc200_to_yeo7_mapping.csv')\ncc200_to_yeo7_mapping = dict(zip(df['CC200_Region'], df['Yeo7_Network'])) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:43:50.935562Z","iopub.execute_input":"2025-04-18T07:43:50.935870Z","iopub.status.idle":"2025-04-18T07:43:51.208157Z","shell.execute_reply.started":"2025-04-18T07:43:50.935839Z","shell.execute_reply":"2025-04-18T07:43:51.207570Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(\"Phenotypic_V1_0b_preprocessed1.csv\")\ndf = df[[\"FILE_ID\", \"DX_GROUP\"]]\nlabels_mapping = dict(zip(df[\"FILE_ID\"], df[\"DX_GROUP\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:43:51.208845Z","iopub.execute_input":"2025-04-18T07:43:51.209075Z","iopub.status.idle":"2025-04-18T07:43:51.235986Z","shell.execute_reply.started":"2025-04-18T07:43:51.209059Z","shell.execute_reply":"2025-04-18T07:43:51.235496Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# had to fix this here cuz pytorch cross entropy loss needs 0 and 1 not 1 and 2\nnew_labels_mapping = {}\nfor key, value in labels_mapping.items():\n    new_labels_mapping[key] = value - 1  # Subtract 1 to convert 1,2 to 0,1\n\n# Recreate your dataset with adjusted labels\ndataset = CC200Data(\"/kaggle/input/autistic-brains/Outputs/cpac/nofilt_noglobal/rois_cc200\", cc200_to_yeo7_mapping, new_labels_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:43:51.236624Z","iopub.execute_input":"2025-04-18T07:43:51.236837Z","iopub.status.idle":"2025-04-18T07:44:08.666779Z","shell.execute_reply.started":"2025-04-18T07:43:51.236821Z","shell.execute_reply":"2025-04-18T07:44:08.665879Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: divide by zero encountered in divide\n  c /= stddev[:, None]\n/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n  c /= stddev[:, None]\n/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: divide by zero encountered in divide\n  c /= stddev[None, :]\n/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n  c /= stddev[None, :]\n/tmp/ipykernel_31/1401220553.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  self.region_coeff = torch.tensor([self._region_coeffs(i) for i in self.files], dtype=torch.float32)\n","output_type":"stream"},{"name":"stdout","text":"[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 2 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 3 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 1 constant columns.\n[INFO] File NYU_0051123_rois_cc200.1D - Region 1 has 19 constant columns.\n[INFO] File Pitt_0050045_rois_cc200.1D - Region 2 has 13 constant columns.\n[INFO] File USM_0050443_rois_cc200.1D - Region 3 has 16 constant columns.\n[INFO] File Stanford_0051165_rois_cc200.1D - Region 4 has 9 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 7 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 15 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 1 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 9 constant columns.\n[INFO] File NYU_0051123_rois_cc200.1D - Region 1 has 23 constant columns.\n[INFO] File Pitt_0050045_rois_cc200.1D - Region 2 has 11 constant columns.\n[INFO] File USM_0050443_rois_cc200.1D - Region 3 has 12 constant columns.\n[INFO] File Stanford_0051165_rois_cc200.1D - Region 4 has 10 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 12 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 13 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 28 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 2 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 4 constant columns.\n[INFO] File USM_0050443_rois_cc200.1D - Region 3 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 4 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 2 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 2 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 3 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 3 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 2 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 2 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 4 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 2 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 2 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 6 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 1 constant columns.\n[INFO] File Pitt_0050045_rois_cc200.1D - Region 2 has 7 constant columns.\n[INFO] File USM_0050443_rois_cc200.1D - Region 3 has 3 constant columns.\n[INFO] File Stanford_0051165_rois_cc200.1D - Region 4 has 2 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 4 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 6 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 5 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 5 constant columns.\n[INFO] File NYU_0051123_rois_cc200.1D - Region 1 has 3 constant columns.\n[INFO] File USM_0050443_rois_cc200.1D - Region 3 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 3 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 4 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 4 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 4 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 3 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 3 constant columns.\n[INFO] File NYU_0051123_rois_cc200.1D - Region 1 has 1 constant columns.\n[INFO] File USM_0050443_rois_cc200.1D - Region 3 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 4 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 4 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 1 constant columns.\n[INFO] File USM_0050443_rois_cc200.1D - Region 3 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 3 constant columns.\n[INFO] File Pitt_0050045_rois_cc200.1D - Region 2 has 1 constant columns.\n[INFO] File Stanford_0051165_rois_cc200.1D - Region 4 has 1 constant columns.\n[INFO] File UM_1_0050315_rois_cc200.1D - Region 0 has 1 constant columns.\n[INFO] File NYU_0051123_rois_cc200.1D - Region 1 has 1 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 11 constant columns.\n[INFO] File NYU_0050993_rois_cc200.1D - Region 6 has 6 constant columns.\n[INFO] File UCLA_1_0051211_rois_cc200.1D - Region 7 has 8 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 2 constant columns.\n[INFO] File MaxMun_c_0051340_rois_cc200.1D - Region 5 has 1 constant columns.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_loader = DataLoader(dataset, batch_size=16, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.669229Z","iopub.execute_input":"2025-04-18T07:44:08.669509Z","iopub.status.idle":"2025-04-18T07:44:08.673670Z","shell.execute_reply.started":"2025-04-18T07:44:08.669487Z","shell.execute_reply":"2025-04-18T07:44:08.672906Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"unique_labels = set()\nfor _, _, labels in train_loader:\n    unique_labels.update(labels.numpy())\nprint(f\"updated label values: {sorted(list(unique_labels))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.674386Z","iopub.execute_input":"2025-04-18T07:44:08.674611Z","iopub.status.idle":"2025-04-18T07:44:08.769367Z","shell.execute_reply.started":"2025-04-18T07:44:08.674595Z","shell.execute_reply":"2025-04-18T07:44:08.768646Z"}},"outputs":[{"name":"stdout","text":"updated label values: [0, 1]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"shapes = []\na = next(iter(dataset))[1]\nfor i in a:\n    shapes.append(i.shape[0])\n\n# len(shapes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.769962Z","iopub.execute_input":"2025-04-18T07:44:08.770225Z","iopub.status.idle":"2025-04-18T07:44:08.776237Z","shell.execute_reply.started":"2025-04-18T07:44:08.770204Z","shell.execute_reply":"2025-04-18T07:44:08.774995Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MHSA(nn.Module):\n    def __init__(self, embd_dim, num_heads):\n        super().__init__()\n        self.embd_dim = embd_dim\n        self.num_heads = num_heads\n        self.head_size = self.embd_dim // self.num_heads\n        self.q = nn.Linear(self.embd_dim, self.embd_dim)\n        self.k = nn.Linear(self.embd_dim, self.embd_dim)\n        self.v = nn.Linear(self.embd_dim, self.embd_dim)\n        self.d = self.head_size ** 0.5\n        self.mlp = nn.Linear(self.embd_dim, self.embd_dim)\n        self.layer_norm = nn.LayerNorm(self.embd_dim)  \n        \n    def forward(self, x):\n        batch_size, M, _ = x.shape\n        norm = self.layer_norm(x)\n        q = self.q(norm).view(batch_size, M, self.num_heads, self.head_size).transpose(1, 2)\n        k = self.k(norm).view(batch_size, M, self.num_heads, self.head_size).transpose(1, 2)\n        v = self.v(norm).view(batch_size, M, self.num_heads, self.head_size).transpose(1, 2)\n        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / self.d\n        attn_scores = attn_scores.masked_fill(torch.eye(M, device=x.device).bool(), float('-inf'))\n        attn_weights = F.softmax(attn_scores, dim=-1)\n        context = torch.matmul(attn_weights, v).transpose(1, 2).reshape(batch_size, M, self.embd_dim)\n        out = self.mlp(context)\n        return out + x, attn_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.776687Z","iopub.execute_input":"2025-04-18T07:44:08.776855Z","iopub.status.idle":"2025-04-18T07:44:08.791260Z","shell.execute_reply.started":"2025-04-18T07:44:08.776842Z","shell.execute_reply":"2025-04-18T07:44:08.790506Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class SubnetworkEmbedder(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, output_dim=128):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim),\n        )\n\n    def forward(self, x):\n        return self.mlp(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.792105Z","iopub.execute_input":"2025-04-18T07:44:08.792301Z","iopub.status.idle":"2025-04-18T07:44:08.804933Z","shell.execute_reply.started":"2025-04-18T07:44:08.792287Z","shell.execute_reply":"2025-04-18T07:44:08.804279Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class RegionEmbedder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.region_conv = nn.Conv2d(1, 1, kernel_size=1)\n        self.mlp = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim),\n        )       \n\n    def forward(self, x):\n        x_conv = self.region_conv(x.unsqueeze(1)) \n        x_conv = x_conv.squeeze(1)  \n        return self.mlp(x_conv)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.805634Z","iopub.execute_input":"2025-04-18T07:44:08.805852Z","iopub.status.idle":"2025-04-18T07:44:08.816544Z","shell.execute_reply.started":"2025-04-18T07:44:08.805837Z","shell.execute_reply":"2025-04-18T07:44:08.815979Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class RegionEncoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, embd_dim, num_heads, num_layers):\n        super().__init__()\n        self.reg_embd = RegionEmbedder(input_dim, hidden_dim, embd_dim)\n        self.mhsa_layers = nn.ModuleList([MHSA(embd_dim, num_heads) for _ in range(num_layers)])\n\n    def forward(self, x):\n        x_reg = self.reg_embd(x)\n        x_in = x_reg\n        attn_weights_all = []\n        for mhsa in self.mhsa_layers:\n            x_in, attn_weights = mhsa(x_in)\n            attn_weights_all.append(attn_weights)\n        \n        return x_reg + x_in, torch.stack(attn_weights_all).permute(1, 0, 2, 3, 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.817460Z","iopub.execute_input":"2025-04-18T07:44:08.817717Z","iopub.status.idle":"2025-04-18T07:44:08.833511Z","shell.execute_reply.started":"2025-04-18T07:44:08.817694Z","shell.execute_reply":"2025-04-18T07:44:08.832767Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class SubNetworkEncoder(nn.Module):\n    def __init__(self, shapes, hidden_dim, embd_dim, num_heads, num_layers):\n        super().__init__()\n        self.embd_dim = embd_dim\n        self.mlps = [SubnetworkEmbedder(i, hidden_dim, embd_dim) for i in shapes]\n        self.mhsa_layers = nn.ModuleList([MHSA(embd_dim, num_heads) for _ in range(num_layers)])\n\n    def forward(self, x):\n        batch_size = x[0].shape[0]\n        x = torch.stack([mlp(f) for mlp, f in zip(self.mlps, x)], dim=1)\n        attn_weights_all = []\n        for mhsa in self.mhsa_layers:\n            x, attn_weights = mhsa(x)\n            attn_weights_all.append(attn_weights)\n\n        return x, torch.stack(attn_weights_all).permute(1, 0, 2, 3, 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.834146Z","iopub.execute_input":"2025-04-18T07:44:08.834359Z","iopub.status.idle":"2025-04-18T07:44:08.845880Z","shell.execute_reply.started":"2025-04-18T07:44:08.834345Z","shell.execute_reply":"2025-04-18T07:44:08.845156Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model = SubNetworkEncoder(shapes, 256, 128, 8, 4)\na = next(iter(train_loader))[1]\nmodel(a)[1].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.846628Z","iopub.execute_input":"2025-04-18T07:44:08.846799Z","iopub.status.idle":"2025-04-18T07:44:08.925038Z","shell.execute_reply.started":"2025-04-18T07:44:08.846785Z","shell.execute_reply":"2025-04-18T07:44:08.924307Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 4, 8, 8, 8])"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"b = next(iter(train_loader))[0]\nmodel1 = RegionEncoder(185, 256, 128, 8, 4)\nmodel1(b)[1].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:08.925870Z","iopub.execute_input":"2025-04-18T07:44:08.926114Z","iopub.status.idle":"2025-04-18T07:44:09.243240Z","shell.execute_reply.started":"2025-04-18T07:44:08.926099Z","shell.execute_reply":"2025-04-18T07:44:09.242473Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 4, 8, 185, 185])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"class StepOne(nn.Module):\n    def __init__(self, input_dim, hidden_dim, embd_dim, num_heads, num_layers):\n        super().__init__()\n        self.reg_enc = RegionEncoder(input_dim, hidden_dim, embd_dim, num_heads, num_layers)\n        self.subnet_enc = SubNetworkEncoder(shapes, hidden_dim, embd_dim, num_heads, num_layers)\n        self.layer_norm = nn.LayerNorm(embd_dim)\n        self.mlp = nn.Sequential(\n            nn.Linear(embd_dim, hidden_dim),  \n            nn.ReLU(),             \n            nn.Linear(hidden_dim, embd_dim)    \n        )\n        self.region_start_indices = list(dataset.region_start_indices.values()) + [185]\n\n    def subNetworkAttendRegions(self, subnet_attn_map, region_attn_map):\n        region_to_subnet = torch.zeros(185, dtype=torch.long)\n        for subnet_id in range(7):\n            start = self.region_start_indices[subnet_id]\n            end = self.region_start_indices[subnet_id + 1]\n            region_to_subnet[start:end] = subnet_id  \n        subnet_i = region_to_subnet.view(-1, 1).expand(185, 185) \n        subnet_j = region_to_subnet.view(1, -1).expand(185, 185)  \n\n        mask = subnet_i != subnet_j  \n\n        attn_multiplier = subnet_attn_map[:, :, :, subnet_i, subnet_j]  \n        attn_multiplier = attn_multiplier * mask\n\n        return region_attn_map * attn_multiplier \n    \n    def sinkhorn(self, attn, n_iters=5, eps=1e-6):\n        attn = attn + eps  \n        for _ in range(n_iters):\n            attn = attn / attn.sum(dim=-1, keepdim=True)\n            attn = attn / attn.sum(dim=-2, keepdim=True)\n        return attn\n    \n    def forward(self, x):\n        x0 = self.reg_enc(x[0])\n        x1 = self.subnet_enc(x[1])\n        o = torch.cat((x0[0], x1[0]), dim=1)\n        o_norm = self.layer_norm(o)\n        o_norm = self.mlp(o)\n        o = o + o_norm\n        o_reg = o[:, :186, :]\n        o_sub = o[:, 186:, :]\n        adj_matrix = self.subNetworkAttendRegions(x1[1], x0[1])\n        adj_matrix = self.sinkhorn(adj_matrix)\n        return o_reg, o_sub, adj_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:09.244121Z","iopub.execute_input":"2025-04-18T07:44:09.244996Z","iopub.status.idle":"2025-04-18T07:44:09.253054Z","shell.execute_reply.started":"2025-04-18T07:44:09.244971Z","shell.execute_reply":"2025-04-18T07:44:09.252446Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model = StepOne(185, 256, 128, 16, 4)\na = model(next(iter(train_loader)))[2]\na.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:09.253855Z","iopub.execute_input":"2025-04-18T07:44:09.254418Z","iopub.status.idle":"2025-04-18T07:44:10.641467Z","shell.execute_reply.started":"2025-04-18T07:44:09.254394Z","shell.execute_reply":"2025-04-18T07:44:10.640859Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 4, 16, 185, 185])"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"# HGCN part now","metadata":{}},{"cell_type":"code","source":"class HGCN(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        \n        # Create weight matrices for each layer and head - just for regions (since we've alreay weigted them)\n        self.W_reg = nn.ModuleList([\n            nn.ModuleList([\n                nn.Linear(input_dim, output_dim) for _ in range(16)  # 16 heads\n            ]) for _ in range(4)  # 4 layers\n        ])\n        \n        self.activation = nn.ReLU()\n    \n    def forward(self, features, attention_maps):\n        batch_size, num_layers, num_heads, num_nodes, _ = attention_maps.shape\n        all_outputs = []\n        \n        # go layer by layer\n        for l in range(num_layers):\n            layer_outputs = []\n            # head by head\n            for h in range(num_heads):\n                # Get attention map for THIS layer and head\n                A_l_c = attention_maps[:, l, h]\n                \n                # Transform feature with layer and head specific weights\n                W_l_c = self.W_reg[l][h]\n                transformed_features = W_l_c(features)  # [batch_size, num_nodes, output_dim]\n                \n                # graph convolution like in paper\n                O_l_c = torch.bmm(A_l_c, transformed_features)  # [batch_size, num_nodes, output_dim]\n                O_l_c = self.activation(O_l_c)\n                \n                layer_outputs.append(O_l_c)\n            \n            # Concatenate outputs from all heads for THIS layer\n            layer_output = torch.cat(layer_outputs, dim=2)  # [batch_size, num_nodes, output_dim*num_heads]\n            all_outputs.append(layer_output)\n        \n        # concatenate outputs from ALL layers\n        # Z = ‚à•·¥∏‚Çó‚Çå‚ÇÅ(‚à•·∂úùíÑ‚Çå‚ÇÅ OÃÖÀ°'·∂ú)\n        final_output = torch.cat(all_outputs, dim=2)  # [batch_size, num_nodes, output_dim*num_heads*num_layers]\n        \n        return final_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:10.642256Z","iopub.execute_input":"2025-04-18T07:44:10.642941Z","iopub.status.idle":"2025-04-18T07:44:10.649212Z","shell.execute_reply.started":"2025-04-18T07:44:10.642921Z","shell.execute_reply":"2025-04-18T07:44:10.648474Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class StepOneWithHGCN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, embd_dim, num_heads, num_layers, num_classes=2):\n        super().__init__()\n        # Copy paste\n        self.reg_enc = RegionEncoder(input_dim, hidden_dim, embd_dim, num_heads, num_layers)\n        self.subnet_enc = SubNetworkEncoder(shapes, hidden_dim, embd_dim, num_heads, num_layers)\n        self.layer_norm = nn.LayerNorm(embd_dim)\n        self.mlp = nn.Sequential(\n            nn.Linear(embd_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, embd_dim)\n        )\n        self.region_start_indices = list(dataset.region_start_indices.values()) + [185]\n        \n        # Adding HGCN\n        # For each head, we reduce dimension to embd_dim/num_heads\n        self.hgcn = HGCN(input_dim=embd_dim, output_dim=embd_dim//num_heads)\n        \n        # Classifier for final prediction\n        hgcn_output_dim = (embd_dim//num_heads) * num_heads * num_layers\n        self.classifier = nn.Sequential(\n            nn.Linear(hgcn_output_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim, num_classes)\n        )\n    \n    def subNetworkAttendRegions(self, subnet_attn_map, region_attn_map):\n        region_to_subnet = torch.zeros(185, dtype=torch.long)\n        for subnet_id in range(7):\n            start = self.region_start_indices[subnet_id]\n            end = self.region_start_indices[subnet_id + 1]\n            region_to_subnet[start:end] = subnet_id\n        subnet_i = region_to_subnet.view(-1, 1).expand(185, 185)\n        subnet_j = region_to_subnet.view(1, -1).expand(185, 185)\n        mask = subnet_i != subnet_j\n        attn_multiplier = subnet_attn_map[:, :, :, subnet_i, subnet_j]\n        attn_multiplier = attn_multiplier * mask\n        return region_attn_map * attn_multiplier\n    \n    def sinkhorn(self, attn, n_iters=5, eps=1e-6):\n        attn = attn + eps\n        for _ in range(n_iters):\n            attn = attn / attn.sum(dim=-1, keepdim=True)\n            attn = attn / attn.sum(dim=-2, keepdim=True)\n        return attn\n    \n    def forward(self, x):\n        # Step One processing\n        x0, region_attn = self.reg_enc(x[0])\n        x1, subnet_attn = self.subnet_enc(x[1])\n        \n        o = torch.cat((x0, x1), dim=1)\n        o_norm = self.layer_norm(o)\n        o_norm = self.mlp(o_norm)\n        o = o + o_norm\n        \n        o_reg = o[:, :185, :]  # First 185 nodes are regions\n        o_sub = o[:, 185:, :]  # Remaining nodes are subnetworks\n        \n        # Process attention maps to create the combined attention \n        # with shape [batch_size, num_layers (4), num_heads (16), 185, 185]\n        combined_attn = self.subNetworkAttendRegions(subnet_attn, region_attn)\n        combined_attn = self.sinkhorn(combined_attn)\n        \n        # Pass through HGCN - only process the region features with the combined attention\n        hgcn_output = self.hgcn(o_reg, combined_attn)\n        \n        # Global average pooling for classification\n        pooled_output = hgcn_output.mean(dim=1)  # [batch_size, output_dim*num_heads*num_layers]\n        \n        # Final classif\n        logits = self.classifier(pooled_output)\n        \n        return logits, o_reg, o_sub, combined_attn, hgcn_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:10.650061Z","iopub.execute_input":"2025-04-18T07:44:10.650842Z","iopub.status.idle":"2025-04-18T07:44:10.668373Z","shell.execute_reply.started":"2025-04-18T07:44:10.650825Z","shell.execute_reply":"2025-04-18T07:44:10.667768Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"for param in model.parameters():\n    print(param.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:44:10.668996Z","iopub.execute_input":"2025-04-18T07:44:10.669324Z","iopub.status.idle":"2025-04-18T07:44:10.683562Z","shell.execute_reply.started":"2025-04-18T07:44:10.669309Z","shell.execute_reply":"2025-04-18T07:44:10.683049Z"}},"outputs":[{"name":"stdout","text":"cpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\ncpu\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model = StepOneWithHGCN(\n    input_dim=185,\n    hidden_dim=256,\n    embd_dim=128,\n    num_heads=16,\n    num_layers=4,\n    num_classes=2\n)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()  # For classification\n\nnum_epochs = 50\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for batch_idx, (region_data, subnetwork_data, labels) in enumerate(train_loader):\n        region_data = region_data.to(device)\n        subnetwork_data = [subnet.to(device) for subnet in subnetwork_data] \n        labels = labels.to(device)\n        # I MOVED EVERYTHING ALREADY\n\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        x = (region_data, subnetwork_data)\n        logits, _, _, _, _ = model(x)\n        \n        loss = criterion(logits, labels)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(logits.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        if (batch_idx + 1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], '\n                  f'Loss: {running_loss/10:.4f}, Accuracy: {100*correct/total:.2f}%')\n            running_loss = 0.0\n\ntorch.save(model.state_dict(), 'brain_network_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T07:46:10.489601Z","iopub.execute_input":"2025-04-18T07:46:10.490462Z","iopub.status.idle":"2025-04-18T07:46:10.569993Z","shell.execute_reply.started":"2025-04-18T07:46:10.490438Z","shell.execute_reply":"2025-04-18T07:46:10.568852Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3860425029.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregion_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubnetwork_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/989949419.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Step One processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubnet_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubnet_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/3516531640.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mattn_weights_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmhsa\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmhsa_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/3516531640.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mattn_weights_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmhsa\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmhsa_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1924444035.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"],"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}