{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11415041,"sourceType":"datasetVersion","datasetId":7100347}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset\nimport torch\nimport numpy as np\n\n\nclass CC200Data(Dataset):\n    def __init__(self, path, mapping):\n        super().__init__()\n        self.path = path\n        self.mapping = mapping\n        self.folder = os.listdir(self.path)\n        self.files = [np.loadtxt(f\"{path}/{i}\") for i in self.folder]\n        self.region_coeff = torch.tensor([np.corrcoef(i, rowvar=False) for i in self.files], dtype=torch.float32)\n        self.subnetwork_coeff = [self._subnetwork_coeffs(i) for i in self.files]\n        \n    def _region_mapping(self, x):\n        region_indices = {i: [] for i in range(1, 8)}\n        for i, j in self.mapping.items():\n            if j == 0:\n                continue\n            region_indices[j].append(i - 1)\n        return region_indices\n\n    def _subnetwork_coeffs(self, x):\n        region_indices = self._region_mapping(x)\n        correlation_matrices = []\n        for i in region_indices.keys():\n            m = x[:, region_indices[i]]\n            correlation_matrix = np.corrcoef(m, rowvar=False)\n            correlation_matrices.append(torch.tensor(self._flatten_matrix(correlation_matrix), dtype=torch.float32))\n        return correlation_matrices\n        \n    def _flatten_matrix(self, matrix):\n        idx = np.triu_indices_from(matrix, k=1)\n        return matrix[idx]\n    \n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        region_corr = self.region_coeff[idx]\n        subnetwork_corrs = self.subnetwork_coeff[idx]\n        return region_corr, subnetwork_corrs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T07:58:13.287600Z","iopub.execute_input":"2025-04-16T07:58:13.287925Z","iopub.status.idle":"2025-04-16T07:58:13.298811Z","shell.execute_reply.started":"2025-04-16T07:58:13.287901Z","shell.execute_reply":"2025-04-16T07:58:13.297681Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/broccubali/AutisticAdventures/main/cc200_to_yeo7_mapping.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T07:55:55.305059Z","iopub.execute_input":"2025-04-16T07:55:55.305391Z","iopub.status.idle":"2025-04-16T07:55:55.637357Z","shell.execute_reply.started":"2025-04-16T07:55:55.305364Z","shell.execute_reply":"2025-04-16T07:55:55.635960Z"}},"outputs":[{"name":"stdout","text":"--2025-04-16 07:55:55--  https://raw.githubusercontent.com/broccubali/AutisticAdventures/main/cc200_to_yeo7_mapping.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1319 (1.3K) [text/plain]\nSaving to: ‘cc200_to_yeo7_mapping.csv’\n\ncc200_to_yeo7_mappi 100%[===================>]   1.29K  --.-KB/s    in 0s      \n\n2025-04-16 07:55:55 (36.4 MB/s) - ‘cc200_to_yeo7_mapping.csv’ saved [1319/1319]\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/working/cc200_to_yeo7_mapping.csv')\ncc200_to_yeo7_mapping = dict(zip(df['CC200_Region'], df['Yeo7_Network'])) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T07:55:57.715034Z","iopub.execute_input":"2025-04-16T07:55:57.716088Z","iopub.status.idle":"2025-04-16T07:55:58.121654Z","shell.execute_reply.started":"2025-04-16T07:55:57.716046Z","shell.execute_reply":"2025-04-16T07:55:58.120391Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dataset = CC200Data(\"/kaggle/input/autistic-brains/Outputs/cpac/nofilt_noglobal/rois_cc200\", cc200_to_yeo7_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T07:58:16.741599Z","iopub.execute_input":"2025-04-16T07:58:16.741949Z","iopub.status.idle":"2025-04-16T07:58:23.983947Z","shell.execute_reply.started":"2025-04-16T07:58:16.741925Z","shell.execute_reply":"2025-04-16T07:58:23.983080Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"shapes = []\na = next(iter(dataset))[1]\nfor i in a:\n    shapes.append(i.shape[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T07:58:26.076253Z","iopub.execute_input":"2025-04-16T07:58:26.076630Z","iopub.status.idle":"2025-04-16T07:58:26.094804Z","shell.execute_reply.started":"2025-04-16T07:58:26.076607Z","shell.execute_reply":"2025-04-16T07:58:26.093660Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_loader = DataLoader(dataset, batch_size=64, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T07:58:27.724655Z","iopub.execute_input":"2025-04-16T07:58:27.725031Z","iopub.status.idle":"2025-04-16T07:58:27.730144Z","shell.execute_reply.started":"2025-04-16T07:58:27.725008Z","shell.execute_reply":"2025-04-16T07:58:27.729054Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MHSA(nn.Module):\n    def __init__(self, embd_dim, num_heads):\n        super().__init__()\n        self.embd_dim = embd_dim\n        self.num_heads = num_heads\n        self.head_size = self.embd_dim // self.num_heads\n        self.q = nn.Linear(self.embd_dim, self.embd_dim)\n        self.k = nn.Linear(self.embd_dim, self.embd_dim)\n        self.v = nn.Linear(self.embd_dim, self.embd_dim)\n        self.d = self.head_size ** 0.5\n        self.mlp = nn.Linear(self.embd_dim, self.embd_dim)\n        self.layer_norm = nn.LayerNorm(self.embd_dim)  \n        \n    def forward(self, x):\n        batch_size, M, _ = x.shape\n        norm = self.layer_norm(x)\n        q = self.q(norm).view(batch_size, M, self.num_heads, self.head_size).transpose(1, 2)\n        k = self.k(norm).view(batch_size, M, self.num_heads, self.head_size).transpose(1, 2)\n        v = self.v(norm).view(batch_size, M, self.num_heads, self.head_size).transpose(1, 2)\n\n        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / self.d\n        attn_scores = attn_scores.masked_fill(torch.eye(M, device=x.device).bool(), float('-inf'))\n        attn_weights = F.softmax(attn_scores, dim=-1)\n        \n        context = torch.matmul(attn_weights, v).transpose(1, 2).reshape(batch_size, M, self.embd_dim)\n        out = self.mlp(context)\n        return out + x, attn_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:10:22.355272Z","iopub.execute_input":"2025-04-16T08:10:22.356208Z","iopub.status.idle":"2025-04-16T08:10:22.365779Z","shell.execute_reply.started":"2025-04-16T08:10:22.356178Z","shell.execute_reply":"2025-04-16T08:10:22.364964Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"class SubnetworkEmbedder(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, output_dim=128):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim),\n        )\n\n    def forward(self, x):\n        return self.mlp(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:10:22.641641Z","iopub.execute_input":"2025-04-16T08:10:22.641966Z","iopub.status.idle":"2025-04-16T08:10:22.648386Z","shell.execute_reply.started":"2025-04-16T08:10:22.641942Z","shell.execute_reply":"2025-04-16T08:10:22.646859Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"class RegionEmbedder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.region_conv = nn.Conv2d(1, 1, kernel_size=1)\n        self.mlp = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim),\n        )       \n\n    def forward(self, x):\n        x_conv = self.region_conv(x.unsqueeze(1)) \n        x_conv = x_conv.squeeze(1)  \n        return self.mlp(x_conv)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:10:24.030320Z","iopub.execute_input":"2025-04-16T08:10:24.030943Z","iopub.status.idle":"2025-04-16T08:10:24.036547Z","shell.execute_reply.started":"2025-04-16T08:10:24.030917Z","shell.execute_reply":"2025-04-16T08:10:24.035468Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"class RegionEncoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, embd_dim, num_heads):\n        super().__init__()\n        self.reg_embd = RegionEmbedder(input_dim, hidden_dim, embd_dim)\n        self.mhsa = MHSA(embd_dim, num_heads)\n\n    def forward(self, x):\n        x_reg = self.reg_embd(x)  \n\n        attn_out, attn_weights = self.mhsa(x_reg)  \n        return x_reg + attn_out, attn_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:10:24.243293Z","iopub.execute_input":"2025-04-16T08:10:24.243873Z","iopub.status.idle":"2025-04-16T08:10:24.249205Z","shell.execute_reply.started":"2025-04-16T08:10:24.243846Z","shell.execute_reply":"2025-04-16T08:10:24.248362Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"class SubNetworkEncoder(nn.Module):\n    def __init__(self, shapes, hidden_dim, embd_dim, num_heads):\n        super().__init__()\n        self.embd_dim = embd_dim\n        self.mlps = [SubnetworkEmbedder(i, hidden_dim, embd_dim) for i in shapes]\n        self.mhsa = MHSA(embd_dim, num_heads)\n\n    def forward(self, x):\n        batch_size = x[0].shape[0]\n        x = torch.cat([mlp(f) for mlp, f in zip(self.mlps, x)]).view(batch_size, 7, self.embd_dim)\n        return self.mhsa(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:11:46.918671Z","iopub.execute_input":"2025-04-16T08:11:46.918970Z","iopub.status.idle":"2025-04-16T08:11:46.925371Z","shell.execute_reply.started":"2025-04-16T08:11:46.918949Z","shell.execute_reply":"2025-04-16T08:11:46.924405Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"model = SubNetworkEncoder(shapes, 256, 128, 8)\na = next(iter(train_loader))[1]\nmodel(a)[0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:11:54.263752Z","iopub.execute_input":"2025-04-16T08:11:54.264062Z","iopub.status.idle":"2025-04-16T08:11:54.297902Z","shell.execute_reply.started":"2025-04-16T08:11:54.264042Z","shell.execute_reply":"2025-04-16T08:11:54.296727Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 7, 128])"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"b = next(iter(train_loader))[0]\nmodel1 = RegionEncoder(200, 256, 128, 8)\nmodel1(b)[0].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:11:58.485085Z","iopub.execute_input":"2025-04-16T08:11:58.485407Z","iopub.status.idle":"2025-04-16T08:11:58.952713Z","shell.execute_reply.started":"2025-04-16T08:11:58.485383Z","shell.execute_reply":"2025-04-16T08:11:58.951621Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 200, 128])"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"class StepOne(nn.Module):\n    def __init__(self, input_dim, hidden_dim, embd_dim, num_heads):\n        super().__init__()\n        self.reg_enc = RegionEncoder(input_dim, hidden_dim, embd_dim, num_heads)\n        self.subnet_enc = SubNetworkEncoder(shapes, hidden_dim, embd_dim, num_heads)\n\n    def forward(self, x):\n        x0 = self.reg_enc(x[0])\n        x1 = self.subnet_enc(x[1])\n        return x0, x1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T08:12:22.727172Z","iopub.execute_input":"2025-04-16T08:12:22.727515Z","iopub.status.idle":"2025-04-16T08:12:22.734312Z","shell.execute_reply.started":"2025-04-16T08:12:22.727491Z","shell.execute_reply":"2025-04-16T08:12:22.733287Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"model = StepOne(200, 256, 128, 8)\nmodel(next(iter(train_loader)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}